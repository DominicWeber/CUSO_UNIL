{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# NLP with Flair\n",
        "\n",
        "This notebook is a step-by-step walkthrough of NLP – named entity recognition and part-of-speech tagging specifically.\n",
        "\n",
        "After familiarizing yourself with how it all works and plays together, you should be able to re-use the notebook and adapt it to your needs.\n",
        "\n",
        "The term 'notebook' here refers to this .ipynb-file. It is a file format, which allows for text- and code cells respectively. Code cells can be run directly form the notebook.\n",
        "\n",
        "As we will be running the notebook in Google Colab, no installations are required. Google Colab provides you with a virtual machine which has python and an array of useful packages pre-installed.\n",
        "Keep in mind that Google Colab is a cloud service after all, so if your research involves working with sensitive data it might not be compliant with your data privacy regulations and restrictions."
      ],
      "metadata": {
        "id": "XTwRiPWWRtVr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NER with Flair\n",
        "\n",
        "The goal of named entity extraction (NER) is to identify persons, locations, organisations, and sometimes other concepts too.\n",
        "\n",
        "This notebook uses the NER framework [flair](https://github.com/flairNLP/flair) as it is relatively easy to use and Ismail Prada-Ziegler from DH Unibe has trained an NER-Model for the bernese towerbooks, which will serve as an example here. Spacy is another widely used NER framework, which is also intuitive and powerful."
      ],
      "metadata": {
        "id": "wdF4PeXYOpHk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install flair\n",
        "\n",
        "!pip install flair"
      ],
      "metadata": {
        "id": "bdKHwPTgVCyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJgAYJ5gPCLi"
      },
      "outputs": [],
      "source": [
        "# test_paragraph = \"Namlich das Hanns Mulheim zer wirtshus zu Buchse sol gredt haben von Herren von Bern habind die von Zürich verratten oder wollend sy verratten.\"\n",
        "\n",
        "# First, we need to load the utilities we need from the flair module.\n",
        "from flair.splitter import SegtokSentenceSplitter\n",
        "from flair.models import SequenceTagger"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In order to be able to access the example text we need to upload the txt to\n",
        "# the session storage. You can do this in the files-tab in the sidebar.\n",
        "\n",
        "# Once done, you can read the file into a python object like so.\n",
        "# Is is usually also a good idea to split long text into smaller chunks. This\n",
        "# example can be easily separated at double-newlines.\n",
        "with open('B_IX_452.txt') as f:\n",
        "  text = f.read()"
      ],
      "metadata": {
        "id": "jqSHEmwrdMrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Then we need to load a tagger (model). We can directly use links to\n",
        "# huggingface here. Models tend to be large, so this step can take some time if\n",
        "# executed for the first time. It can also fill up the RAM of your virtual\n",
        "# machine rather quickly, so try not to load multiple models at the same time\n",
        "# but rather restart the runtime if you intend to swith the model.\n",
        "\n",
        "# In this specific case we use the aforementioned model trained on the bernese\n",
        "# towerbooks.\n",
        "tagger = SequenceTagger.load(\"dh-unibe/turmbuecher-ner-v1\")"
      ],
      "metadata": {
        "id": "RceQE0YOXerT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Before we feed the text to the tagger we need to turn it into a Sentence\n",
        "# object, which also tokenizes it.\n",
        "\n",
        "# It can make sense to split long documents into paragraphs before prediction\n",
        "# as most systems perform worse on long texts, which is why we use the built\n",
        "# in splitter.\n",
        "splitter = SegtokSentenceSplitter()\n",
        "sentences = splitter.split(text)\n",
        "\n",
        "# Here we actually identify the named entities. This can take a while.\n",
        "tagger.predict(sentences)\n",
        "\n",
        "# print the entities\n",
        "for sentence in sentences:\n",
        "  for entity in sentence.get_spans('ner'):\n",
        "    print(entity)"
      ],
      "metadata": {
        "id": "VGbPYXOuYa6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As expected, this model works very well for the text we fed it. This is mainly because it is fine-tuned on the corpus the text is extracted from, so we can expect it to perform well on similar text.\n",
        "\n",
        "For your own project in the context of this workshop it is recommended to look for suitable models on https://huggingface.co/ instead of using the model we used above."
      ],
      "metadata": {
        "id": "HsRO6glV0mLH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## POS-tagging with Flair\n",
        "\n",
        "Part-of-speech tagging works the same in Flair. The only difference is that we likely have to use a different model and that we have to load a Classifier instead of a SequenceTagger. We will use the same text as an example again."
      ],
      "metadata": {
        "id": "zgZCa-gSQVEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install and load requirements and text in case you start here\n",
        "# (uncomment if necessary)\n",
        "# !pip install flair\n",
        "\n",
        "from flair.nn import Classifier\n",
        "from flair.splitter import SegtokSentenceSplitter\n",
        "\n",
        "with open('B_IX_452.txt') as f:\n",
        "  text = f.read()\n",
        "\n",
        "# Now we are loading a different model. In this case a build-in model for german\n",
        "# pos-tagging, just to see how it works for pre-modern texts.\n",
        "tagger = Classifier.load(\"de-pos\")\n",
        "\n",
        "# Finally we split the text into paragraphs again and predict and retrieve the\n",
        "# annotations.\n",
        "splitter = SegtokSentenceSplitter()\n",
        "sentences = splitter.split(text)\n",
        "\n",
        "# Here we actually identify the parts-of-speech. This can take a while.\n",
        "tagger.predict(sentences)\n",
        "\n",
        "# print the parts-of-speech\n",
        "for sentence in sentences:\n",
        "  print(sentence)"
      ],
      "metadata": {
        "id": "kxeZfVeISrMS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}